{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5113c6d-0afe-4d80-839a-796735a23059",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn com.salesforce.transmogrifai transmogrifai-core_2.11 0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0e397e-204f-4a44-9b1c-667107cbe60e",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn org.apache.spark spark-mllib_2.11 2.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.SparkContext\n",
       "import org.apache.spark.sql.functions.udf\n",
       "import com.salesforce.op._\n",
       "import com.salesforce.op.features._\n",
       "import com.salesforce.op.features.types._\n",
       "import com.salesforce.op.stages.impl.classification._\n",
       "import com.salesforce.op.evaluators.Evaluators\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "import com.salesforce.op._\n",
    "import com.salesforce.op.features._\n",
    "import com.salesforce.op.features.types._\n",
    "import com.salesforce.op.stages.impl.classification._\n",
    "import com.salesforce.op.evaluators.Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import com.salesforce.op.OpWorkflow\n",
       "import com.salesforce.op.evaluators.Evaluators\n",
       "import com.salesforce.op.readers.DataReaders\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.salesforce.op.OpWorkflow\n",
    "import com.salesforce.op.evaluators.Evaluators\n",
    "import com.salesforce.op.readers.DataReaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Spark Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@6c425e72"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"SimpleRegression\")\n",
    "implicit val spark = SparkSession.builder.config(conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema and Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class SimpleRegression\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class SimpleRegression (\n",
    "  population: Double,\n",
    "  profit: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = profit, uid = RealNN_000000000002, isResponse = true, originStage = FeatureGeneratorStage_000000000002, parents = [], distributions = [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val population = FeatureBuilder.RealNN[SimpleRegression].extract(_.population.toRealNN).asPredictor\n",
    "val profit = FeatureBuilder.RealNN[SimpleRegression].extract(_.profit.toRealNN).asResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@1e8ac1e6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val trainFilePath = \"../src/main/resources/SimpleRegressionDataset/simple_regression.csv\"\n",
    "val trainDataReader = DataReaders.Simple.csvCase[SimpleRegression](\n",
    "    path = Option(trainFilePath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// check that path exists\n",
    "scala.reflect.io.File(trainFilePath).exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataSplitter_000000000005"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.salesforce.op.stages.impl.tuning.{DataCutter, DataSplitter}\n",
    "val features = Seq(population).transmogrify()\n",
    "val randomSeed = 42L\n",
    "val splitter = DataSplitter(seed = randomSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selector\n",
    "The ModelSelector is an Estimator that uses data to find the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = population-profit_3-stagesApplied_Prediction_00000000000f, uid = Prediction_00000000000f, isResponse = true, originStage = ModelSelector_00000000000f, parents = [RealNN_000000000002,OPVector_000000000004], distributions = [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.salesforce.op.stages.impl.regression.RegressionModelsToTry.{OpGBTRegressor, OpRandomForestRegressor,OpLinearRegression}\n",
    "import com.salesforce.op.stages.impl.regression.RegressionModelSelector\n",
    "\n",
    "val cutter = DataCutter(reserveTestFraction = 0.2, seed = randomSeed)\n",
    "\n",
    "val prediction = RegressionModelSelector\n",
    "      .withCrossValidation(\n",
    "        dataSplitter = Some(splitter), seed = randomSeed,\n",
    "        modelTypesToUse = Seq(OpGBTRegressor, OpRandomForestRegressor)\n",
    "        //modelTypesToUse = Seq(OpLinearRegression)\n",
    "        \n",
    " \n",
    ").setInput(profit, features).getOutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluators and Workflow\n",
    "Factory that performs the evaluation of metrics for regression. The metrics returned are rmse, mse, r2 and mae.\n",
    "* Mean Squared Error (MSE)\t\n",
    "* Root Mean Squared Error (RMSE)\t\n",
    "* Mean Absolute Error (MAE)\t\n",
    "* Coefficient of Determination \n",
    "\n",
    "OpWorkflows create and transform the raw data needed to compute Features fed into them. In addition they optimize the application of Stages needed to create the final Features ensuring optimal computations within the full pipeline DAG. OpWorkflows can be fit to a given dataset using the .train() method. This produces an OpWorkflowModel which can then be saved to disk and applied to another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpRegressionEvaluator_000000000010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = Evaluators.Regression().setLabelCol(profit).\n",
    "      setPredictionCol(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.salesforce.op.OpWorkflowModel@7eda8a5c"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val workflow = new OpWorkflow().setResultFeatures(prediction, profit).setReader(trainDataReader)\n",
    "val workflowModel = workflow.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate:\n",
      "{\n",
      "  \"RootMeanSquaredError\" : 3.172343537076648,\n",
      "  \"MeanSquaredError\" : 10.06376351723198,\n",
      "  \"R2\" : 0.6650990450368588,\n",
      "  \"MeanAbsoluteError\" : 2.300052394510972\n",
      "}\n",
      "+--------------------+-------+---------------------------------------------------------+\n",
      "|key                 |profit |population-profit_3-stagesApplied_Prediction_00000000000f|\n",
      "+--------------------+-------+---------------------------------------------------------+\n",
      "|-2820701744609922157|17.592 |[prediction -> 3.9116793861193053]                       |\n",
      "|-1364364500464464697|9.1302 |[prediction -> 2.7915410250785895]                       |\n",
      "|4775711067767085698 |13.662 |[prediction -> 7.463972327115551]                        |\n",
      "|2713511938805709318 |11.854 |[prediction -> 4.915782218746902]                        |\n",
      "|732041312525985608  |6.8233 |[prediction -> 2.998118778340556]                        |\n",
      "|-2153771554033910381|11.886 |[prediction -> 7.225213414646878]                        |\n",
      "|3708650087469259187 |4.3483 |[prediction -> 4.907971288099772]                        |\n",
      "|8309197671072542121 |12.0   |[prediction -> 7.463972327115551]                        |\n",
      "|-5928360882916562638|6.5987 |[prediction -> 4.809530925951454]                        |\n",
      "|4085646391494361010 |3.8166 |[prediction -> 1.7887647221882295]                       |\n",
      "|-9182158210853397697|3.2522 |[prediction -> 2.863163635556703]                        |\n",
      "|-5545550250462607911|15.505 |[prediction -> 15.634714764457767]                       |\n",
      "|-9064544925330387686|3.1551 |[prediction -> 2.998118778340556]                        |\n",
      "|-4245128931862318626|7.2258 |[prediction -> 7.225213414646878]                        |\n",
      "|4483188632618575031 |0.71618|[prediction -> 2.863163635556703]                        |\n",
      "|-71415947993140952  |3.5129 |[prediction -> 2.043353304470281]                        |\n",
      "|9199096076607872248 |5.3048 |[prediction -> 4.809530925951454]                        |\n",
      "|8580794993334990368 |0.56077|[prediction -> 1.75138500023701]                         |\n",
      "|4429474902834372894 |3.6518 |[prediction -> 4.809530925951454]                        |\n",
      "|-140521534017109316 |5.3893 |[prediction -> 4.915782218746902]                        |\n",
      "+--------------------+-------+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfScoreAndEvaluate = workflowModel.scoreAndEvaluate(evaluator)\n",
    "val dfScore = dfScoreAndEvaluate._1//.withColumnRenamed(\"population-profit_3-stagesApplied_Prediction_000000000011\",\"predicted_profit\")\n",
    "val dfEvaluate = dfScoreAndEvaluate._2\n",
    "println(\"Evaluate:\\n\" + dfEvaluate.toString())\n",
    "\n",
    "dfScore.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
