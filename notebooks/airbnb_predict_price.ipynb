{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%classpath add mvn com.salesforce.transmogrifai transmogrifai-core_2.11 0.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%classpath add mvn org.apache.spark spark-mllib_2.11 2.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "import com.salesforce.op._\n",
    "import com.salesforce.op.features._\n",
    "import com.salesforce.op.features.types._\n",
    "import com.salesforce.op.stages.impl.classification._\n",
    "import com.salesforce.op.evaluators.Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.salesforce.op.OpWorkflow\n",
    "import com.salesforce.op.evaluators.Evaluators\n",
    "import com.salesforce.op.readers.DataReaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val conf = null\n",
    "implicit val spark = null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema and Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//room_type\tneighbourhood\tnumber_of_reviews\tprice\n",
    "case class SimpleRegression (\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val roomType = FeatureBuilder.Text[SimpleRegression].extract(_.roomType.toText).asPredictor\n",
    "val neighbourhood = FeatureBuilder.Text[SimpleRegression].extract(_.neighbourhood.toText).asPredictor\n",
    "val numberOfReviews = FeatureBuilder.Integral[SimpleRegression].extract(_.numberOfReviews.toIntegral).asPredictor\n",
    "\n",
    "val price = FeatureBuilder.RealNN[SimpleRegression].extract(_.price.toRealNN).asResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val trainFilePath = \"./data/listing_three_features.csv\"\n",
    "val trainDataReader = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// check that path exists\n",
    "scala.reflect.io.File(trainFilePath).exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.salesforce.op.stages.impl.tuning.{DataCutter, DataSplitter}\n",
    "val features = null\n",
    "val randomSeed = 42L\n",
    "val splitter = DataSplitter(seed = randomSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selector\n",
    "The ModelSelector is an Estimator that uses data to find the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.salesforce.op.stages.impl.regression.RegressionModelsToTry.{OpGBTRegressor, OpRandomForestRegressor,OpLinearRegression}\n",
    "import com.salesforce.op.stages.impl.regression.RegressionModelsToTry.{OpLinearRegression}\n",
    "import com.salesforce.op.stages.impl.regression.RegressionModelSelector\n",
    "\n",
    "val cutter = DataCutter(reserveTestFraction = 0.2, seed = randomSeed)\n",
    "\n",
    "val prediction = RegressionModelSelector\n",
    "      .withCrossValidation(\n",
    "        dataSplitter = Some(splitter), seed = randomSeed,\n",
    "        //modelTypesToUse = Seq(OpGBTRegressor, OpRandomForestRegressor)\n",
    "        //modelTypesToUse = Seq(OpLinearRegression, \n",
    "        //                      OpRandomForestRegressor)\n",
    "        modelTypesToUse = null\n",
    "        \n",
    " \n",
    ").setInput(price,features).getOutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluators and Workflow\n",
    "Factory that performs the evaluation of metrics for regression. The metrics returned are rmse, mse, r2 and mae.\n",
    "* Mean Squared Error (MSE)\t\n",
    "* Root Mean Squared Error (RMSE)\t\n",
    "* Mean Absolute Error (MAE)\t\n",
    "* Coefficient of Determination \n",
    "\n",
    "OpWorkflows create and transform the raw data needed to compute Features fed into them. In addition they optimize the application of Stages needed to create the final Features ensuring optimal computations within the full pipeline DAG. OpWorkflows can be fit to a given dataset using the .train() method. This produces an OpWorkflowModel which can then be saved to disk and applied to another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val evaluator = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val workflow = null\n",
    "val workflowModel = workflow.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfScoreAndEvaluate = null\n",
    "val dfScore = dfScoreAndEvaluate._1\n",
    "val dfEvaluate = dfScoreAndEvaluate._2\n",
    "println(\"Evaluate:\\n\" + dfEvaluate.toString())\n",
    "\n",
    "dfScore.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "308px",
    "left": "1253.66px",
    "top": "122px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
